{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Benchmarking on MOABB with Braindecode (PyTorch) deep net architectures\n",
        "This example shows how to use MOABB to benchmark a set of Braindecode pipelines (deep learning\n",
        "architectures) on all available datasets.\n",
        "For this example, we will use only 2 datasets to keep the computation time low, but this benchmark is designed\n",
        "to easily scale to many datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<frozen importlib._bootstrap>:219: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
            "<frozen importlib._bootstrap>:219: FutureWarning: mne.io.pick.pick_channels_regexp is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
            "<frozen importlib._bootstrap>:219: FutureWarning: mne.io.pick.channel_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
            "c:\\Users\\Sam\\miniconda3\\envs\\pytgpu\\lib\\site-packages\\moabb\\pipelines\\__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torch Version: 2.2.1+cu121\n",
            "GPU is AVAILABLE\n"
          ]
        }
      ],
      "source": [
        "# Authors: Igor Carrara <igor.carrara@inria.fr>\n",
        "#          Bruno Aristimunha <b.aristimunha@gmail.com>\n",
        "#          Sylvain Chevallier <sylvain.chevallier@universite-paris-saclay.fr>\n",
        "#\n",
        "# License: BSD (3-clause)\n",
        "\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from absl.logging import ERROR, set_verbosity\n",
        "\n",
        "from moabb import benchmark, set_log_level\n",
        "from moabb.analysis.plotting import score_plot\n",
        "from moabb.datasets import BNCI2014_001, BNCI2014_004\n",
        "from moabb.utils import setup_seed\n",
        "\n",
        "\n",
        "set_log_level(\"info\")\n",
        "# Avoid output Warning\n",
        "set_verbosity(ERROR)\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "\n",
        "# Print Information PyTorch\n",
        "print(f\"Torch Version: {torch.__version__}\")\n",
        "\n",
        "# Set up GPU if it is there\n",
        "cuda = torch.cuda.is_available()\n",
        "device = \"cuda\" if cuda else \"cpu\"\n",
        "print(\"GPU is\", \"AVAILABLE\" if cuda else \"NOT AVAILABLE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example, we will use only 2 subjects from the dataset ``BNCI2014_001`` and ``BNCI2014_004``.\n",
        "\n",
        "## Running the benchmark\n",
        "\n",
        "The benchmark is run using the ``benchmark`` function. You need to specify the\n",
        "folder containing the pipelines, the kind of evaluation, and the paradigm\n",
        "to use. By default, the benchmark will use all available datasets for all\n",
        "paradigms listed in the pipelines. You could restrict to specific evaluation and\n",
        "paradigm using the ``evaluations`` and ``paradigms`` arguments.\n",
        "\n",
        "To save computation time, the results are cached. If you want to re-run the\n",
        "benchmark, you can set the ``overwrite`` argument to ``True``.\n",
        "\n",
        "It is possible to indicate the folder to cache the results and the one to save\n",
        "the analysis & figures. By default, the results are saved in the ``results``\n",
        "folder, and the analysis & figures are saved in the ``benchmark`` folder.\n",
        "\n",
        "This code is implemented to run on CPU. If you're using a GPU, do not use multithreading\n",
        "(i.e. set n_jobs=1)\n",
        "\n",
        "In order to allow the benchmark function to work with return_epoch=True (Required to use Braindecode(\n",
        "we need to call each pipeline as \"braindecode_xxx...\", with xxx the name of the model to be\n",
        "handled correctly by the benchmark function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "Given pipeline path ./pipelines_braindecode is not valid",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 12\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# dataset2 = BNCI2014_004()\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# dataset.subject_list = dataset.subject_list[:2]\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# dataset2.subject_list = dataset2.subject_list[:2]\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# datasets = [dataset, dataset2]\u001b[39;00m\n\u001b[0;32m     10\u001b[0m datasets \u001b[38;5;241m=\u001b[39m [dataset]\n\u001b[1;32m---> 12\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mbenchmark\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpipelines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./pipelines_braindecode\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCrossSession\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparadigms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLeftRightImagery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_datasets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresults\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./results/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./benchmark/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Sam\\miniconda3\\envs\\pytgpu\\lib\\site-packages\\moabb\\benchmark.py:130\u001b[0m, in \u001b[0;36mbenchmark\u001b[1;34m(pipelines, evaluations, paradigms, results, overwrite, output, n_jobs, n_jobs_evaluation, plot, contexts, include_datasets, exclude_datasets)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m osp\u001b[38;5;241m.\u001b[39misdir(output):\n\u001b[0;32m    128\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(output)\n\u001b[1;32m--> 130\u001b[0m pipeline_configs \u001b[38;5;241m=\u001b[39m \u001b[43mparse_pipelines_from_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipelines\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m context_params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m contexts \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\Sam\\miniconda3\\envs\\pytgpu\\lib\\site-packages\\moabb\\pipelines\\utils.py:91\u001b[0m, in \u001b[0;36mparse_pipelines_from_directory\u001b[1;34m(dir_path)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_pipelines_from_directory\u001b[39m(dir_path):\n\u001b[0;32m     75\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Takes in the path to a directory with pipeline configuration files and\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m    returns a dictionary of pipelines.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;124;03m        'paradigms': list of class names that are compatible with said pipeline\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(\n\u001b[0;32m     92\u001b[0m         os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(dir_path)\n\u001b[0;32m     93\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGiven pipeline path \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is not valid\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(dir_path)\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;66;03m# get list of config files\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     yaml_files \u001b[38;5;241m=\u001b[39m glob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dir_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.yml\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
            "\u001b[1;31mAssertionError\u001b[0m: Given pipeline path ./pipelines_braindecode is not valid"
          ]
        }
      ],
      "source": [
        "# Set up reproducibility of Tensorflow\n",
        "setup_seed(42)\n",
        "\n",
        "# Restrict this example only to the first two subjects of BNCI2014_001\n",
        "dataset = BNCI2014_001()\n",
        "# dataset2 = BNCI2014_004()\n",
        "# dataset.subject_list = dataset.subject_list[:2]\n",
        "# dataset2.subject_list = dataset2.subject_list[:2]\n",
        "# datasets = [dataset, dataset2]\n",
        "datasets = [dataset]\n",
        "\n",
        "results = benchmark(\n",
        "    pipelines=\"./pipelines_braindecode\",\n",
        "    evaluations=[\"CrossSession\"],\n",
        "    paradigms=[\"LeftRightImagery\"],\n",
        "    include_datasets=datasets,\n",
        "    results=\"./results/\",\n",
        "    overwrite=False,\n",
        "    plot=False,\n",
        "    output=\"./benchmark/\",\n",
        "    n_jobs=-1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The deep learning architectures implemented in MOABB using Braindecode are:\n",
        "\n",
        "- Shallow Convolutional Network [1]_\n",
        "- Deep Convolutional Network [1]_\n",
        "- EEGNetv4 [2]_\n",
        "- EEGInception [3]_\n",
        "\n",
        "Benchmark prints a summary of the results. Detailed results are saved in a\n",
        "pandas dataframe, and can be used to generate figures. The analysis & figures\n",
        "are saved in the ``benchmark`` folder.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "score_plot(results)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n",
        ".. [1] Schirrmeister, R. T., Springenberg, J. T., Fiederer, L. D. J.,\n",
        "   Glasstetter, M., Eggensperger, K., Tangermann, M., ... & Ball, T. (2017).\n",
        "   [Deep learning with convolutional neural networks for EEG decoding and\n",
        "   visualization](https://doi.org/10.1002/hbm.23730).\n",
        "   Human brain mapping, 38(11), 5391-5420.\n",
        ".. [2] Lawhern, V. J., Solon, A. J., Waytowich, N. R., Gordon, S. M.,\n",
        "   Hung, C. P., & Lance, B. J. (2018). [EEGNet: a compact convolutional neural\n",
        "   network for EEG-based brain-computer interfaces.](https://doi.org/10.1088/1741-2552/aace8c)\n",
        "   Journal of neural engineering, 15(5), 056013.\n",
        ".. [3] Santamaria-Vazquez, E., Martinez-Cagigal, V., Vaquerizo-Villar,\n",
        "   F., & Hornero, R. (2020). [EEG-inception: A novel deep convolutional neural network\n",
        "   for assistive ERP-based brain-computer interfaces.](https://doi.org/10.1109/TNSRE.2020.3048106)\n",
        "   IEEE Transactions on Neural Systems and Rehabilitation Engineering\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
