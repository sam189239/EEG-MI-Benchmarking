{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7cGDJ0YJiZbc"
      },
      "outputs": [],
      "source": [
        "from scipy.signal import butter, lfilter\n",
        "import scipy\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as Data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import time\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OtUtmxdg-Gw"
      },
      "source": [
        "# Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_path = \"../data/physionet_processed/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTGqHXL4grJT",
        "outputId": "43dab0bd-80fd-47ae-c3ab-3b1c47896891"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The shape of Dataset_1: (259520, 65)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[-16, -29,   2, ..., -11,  15,   0],\n",
              "       [-56, -54, -27, ...,   1,  21,   0],\n",
              "       [-55, -55, -29, ...,  18,  35,   0],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,   0,   0,   9],\n",
              "       [  0,   0,   0, ...,   0,   0,   9],\n",
              "       [  0,   0,   0, ...,   0,   0,   9]], dtype=int64)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_1=np.load(dataset_path + '1.npy')\n",
        "print('The shape of Dataset_1:', dataset_1.shape)\n",
        "dataset_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIhUIGnmhJ3B"
      },
      "source": [
        "# Filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FdntZhsDp4yN"
      },
      "outputs": [],
      "source": [
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = scipy.signal.lfilter(b, a, data)\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io9Emc6khOOZ",
        "outputId": "669f9b4a-3060-4ee5-f62c-b279ba55608b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The shape of filtered feature: (259520, 64)\n",
            "The shape of dataset_1 after filtering: (259520, 65)\n"
          ]
        }
      ],
      "source": [
        "n_fea = 64  # 64 channels\n",
        "label = dataset_1[:, n_fea: n_fea+1]  # seperate label from feature\n",
        "feature = dataset_1[:, 0:n_fea]\n",
        "feature_f=[]  # feature after filtering\n",
        "\n",
        "# EEG Delta pattern decomposition\n",
        "for i in range(feature.shape[1]):\n",
        "    x = feature[:, i]\n",
        "    fs = 160.0\n",
        "    lowcut = 0.5\n",
        "    highcut = 4.0\n",
        "    y = butter_bandpass_filter(x, lowcut, highcut, fs, order=3)\n",
        "    feature_f.append(y)\n",
        "\n",
        "feature_f=np.array(feature_f).T\n",
        "print('The shape of filtered feature:',feature_f.shape)\n",
        "\n",
        "data_f=np.hstack((feature_f,label))  # stack label to filtered feature\n",
        "print(\"The shape of dataset_1 after filtering:\",data_f.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GG7DFm-LpWiR"
      },
      "outputs": [],
      "source": [
        "def extract(input, n_classes, n_fea, time_window, moving):\n",
        "    xx = input[:, :n_fea]\n",
        "    yy = input[:, n_fea:n_fea + 1]\n",
        "    new_x = []\n",
        "    new_y = []\n",
        "    number = int((xx.shape[0] / moving) - 1)\n",
        "    for i in range(number):\n",
        "        ave_y = np.average(yy[int(i * moving):int(i * moving + time_window)])\n",
        "        if ave_y in range(n_classes + 1):\n",
        "            new_x.append(xx[int(i * moving):int(i * moving + time_window), :])\n",
        "            new_y.append(ave_y)\n",
        "        else:\n",
        "            new_x.append(xx[int(i * moving):int(i * moving + time_window), :])\n",
        "            new_y.append(0)\n",
        "\n",
        "    new_x = np.array(new_x)\n",
        "    new_x = new_x.reshape([-1, n_fea * time_window])\n",
        "    new_y = np.array(new_y)\n",
        "    new_y.shape = [new_y.shape[0], 1]\n",
        "    data = np.hstack((new_x, new_y))\n",
        "    data = np.vstack((data, data[-1]))  # add the last sample again, to make the sample number round\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_reucTkyhjBk",
        "outputId": "940cc00f-ecaa-4fb0-e0fb-c2d6fc1babd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After segmentation, the shape of the data: (32440, 1025)\n"
          ]
        }
      ],
      "source": [
        "n_class = 10  # 0~9 classes ('10:rest' is not considered)\n",
        "segment_length = 16  # selected time window; 16=160*0.1\n",
        "\n",
        "# segment data, check more details about the 'extract' function in BCI_functions.ipynb\n",
        "data_seg = extract(dataset_1, n_classes=n_class, n_fea=n_fea, time_window=segment_length, moving=(segment_length/2))  # 50% overlapping\n",
        "\n",
        "print('After segmentation, the shape of the data:', data_seg.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEf16DdRoOyH",
        "outputId": "647d1ff3-0b82-4621-f174-5b3e301bde64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After segmentation, the shape of the data: (173013, 193)\n"
          ]
        }
      ],
      "source": [
        "# remove instance with label==10 (rest)\n",
        "# removed_label = [2,3,4,5,6,7,8,9,10]  #2,3,4,5,\n",
        "removed_label = []\n",
        "for ll in removed_label:\n",
        "    id = dataset_1[:, -1]!=ll\n",
        "    dataset_1 = dataset_1[id]\n",
        "\n",
        "# data segmentation\n",
        "n_class = int(11-len(removed_label))  # 0~9 classes ('10:rest' is not considered)\n",
        "no_feature = 64  # the number of the features\n",
        "segment_length = 3  # selected time window; 16=160*0.1\n",
        "LR = 0.005  # learning rate\n",
        "EPOCH = 40\n",
        "\n",
        "data_seg = extract(dataset_1, n_classes=n_class, n_fea=no_feature, time_window=segment_length, moving=(segment_length/2))  # 50% overlapping\n",
        "print('After segmentation, the shape of the data:', data_seg.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1HexifPPoqmZ"
      },
      "outputs": [],
      "source": [
        "# split training and test data\n",
        "no_longfeature = no_feature*segment_length\n",
        "data_seg_feature = data_seg[:, :no_longfeature]\n",
        "data_seg_label = data_seg[:, no_longfeature:no_longfeature+1]\n",
        "train_feature, test_feature, train_label, test_label = train_test_split(data_seg_feature, data_seg_label, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3T_BOalozSU",
        "outputId": "2a81aa1d-3be1-4897-faaf-f2b3bb4a1c7a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-17.,  -4.,  13., ...,  55.,  83.,  23.],\n",
              "       [ 48.,  52.,  73., ...,  37.,  12.,  20.],\n",
              "       [ 25.,  28.,  15., ..., -26.,  -5., -51.],\n",
              "       ...,\n",
              "       [-49., -26., -21., ..., -28.,   6., -23.],\n",
              "       [ 29.,  24.,  29., ...,  25.,  -8.,  56.],\n",
              "       [-34., -39., -32., ..., -52., -51., -46.]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbGkmEYiozIe",
        "outputId": "90a3777b-8780-4d4b-fb17-3be1db8beff2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 79.,  67.,  43., ..., -15.,   3., -11.],\n",
              "       [ 91.,  69.,  30., ...,  19.,  43.,  32.],\n",
              "       [  5.,   6.,  -8., ..., -16.,  36., -12.],\n",
              "       ...,\n",
              "       [-66., -50., -69., ..., -29.,  -3.,  13.],\n",
              "       [ 21.,  18.,   2., ...,  63.,  64.,  50.],\n",
              "       [ 21.,  -2.,  -2., ..., -41., -81., -33.]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsuleu7vh6rc"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsa8SoRtoK4b",
        "outputId": "b0437ab9-44ed-4c7a-9e73-834d30c4483b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After normalization, the shape of training feature: (129759, 192) \n",
            "After normalization, the shape of test feature: (43254, 192)\n",
            "After reshape, the shape of training feature: (129759, 3, 64) \n",
            "After reshape, the shape of test feature: (43254, 3, 64)\n"
          ]
        }
      ],
      "source": [
        "# normalization\n",
        "# before normalize reshape data back to raw data shape\n",
        "train_feature_2d = train_feature.reshape([-1, no_feature])\n",
        "test_feature_2d = test_feature.reshape([-1, no_feature])\n",
        "\n",
        "# min-max normalization\n",
        "scaler3 = MinMaxScaler().fit(train_feature)\n",
        "train_fea_norm1 = scaler3.transform(train_feature)\n",
        "test_fea_norm1 = scaler3.transform(test_feature)\n",
        "print('After normalization, the shape of training feature:', train_fea_norm1.shape,\n",
        "      '\\nAfter normalization, the shape of test feature:', test_fea_norm1.shape)\n",
        "\n",
        "# after normalization, reshape data to 3d in order to feed in to LSTM\n",
        "train_fea_norm1 = train_fea_norm1.reshape([-1, segment_length, no_feature])\n",
        "test_fea_norm1 = test_fea_norm1.reshape([-1, segment_length, no_feature])\n",
        "print('After reshape, the shape of training feature:', train_fea_norm1.shape,\n",
        "      '\\nAfter reshape, the shape of test feature:', test_fea_norm1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vyrwygUCiNiq"
      },
      "outputs": [],
      "source": [
        "BATCH_size = train_fea_norm1.shape[0] # use test_data as batch size\n",
        "\n",
        "# feed data into dataloader\n",
        "train_fea_norm1 = torch.tensor(train_fea_norm1).type('torch.FloatTensor')\n",
        "train_label = torch.tensor(train_label.flatten())\n",
        "train_data = Data.TensorDataset(train_fea_norm1, train_label)\n",
        "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_size, shuffle=False)\n",
        "\n",
        "test_fea_norm1 = torch.tensor(test_fea_norm1).type('torch.FloatTensor')\n",
        "test_label = torch.tensor(test_label.flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmVdVuCLh_mA"
      },
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bzbWP7YEqR8K"
      },
      "outputs": [],
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(no_feature*segment_length, 64*4),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(64*4, no_feature*segment_length),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return encoded, decoded\n",
        "\n",
        "autoencoder = AutoEncoder()\n",
        "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=LR)\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "best_acc = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIWSi7uPrUV3"
      },
      "source": [
        "## Classifiers - (Autoencoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qRDFYEV3s0Cm"
      },
      "outputs": [],
      "source": [
        "n_class = int(11-len(removed_label))  # 0~9 classes ('10:rest' is not considered)\n",
        "no_feature = 64  # the number of the features\n",
        "segment_length = 480  # selected time window; 16=160*0.1\n",
        "LR = 0.005  # learning rate\n",
        "EPOCH = 20\n",
        "n_hidden = 128  # number of neurons in hidden layer\n",
        "l2 = 0.001  # the coefficient of l2-norm regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll7S-aCwulOK"
      },
      "source": [
        "### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSjcrArVrT5h",
        "outputId": "0fbd159e-22c9-4653-f6b3-03183c9af433"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LSTM(\n",
            "  (lstm_layer): LSTM(64, 128, num_layers=2, batch_first=True)\n",
            "  (out): Linear(in_features=128, out_features=11, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LSTM, self).__init__()\n",
        "\n",
        "        self.lstm_layer = nn.LSTM(\n",
        "            input_size=no_feature,\n",
        "            hidden_size=n_hidden,         # LSTM hidden unit\n",
        "            num_layers=2,           # number of LSTM layer\n",
        "            bias=True,\n",
        "            batch_first=True,       # input & output will has batch size as 1s dimension. e.g. (batch, segment_length, no_feature)\n",
        "        )\n",
        "\n",
        "        self.out = nn.Linear(n_hidden, n_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        r_out, (h_n, h_c) = self.lstm_layer(x.float(), None)\n",
        "        r_out = F.dropout(r_out, 0.3)\n",
        "\n",
        "        test_output = self.out(r_out[:, -1, :]) # choose r_out at the last time step\n",
        "        return test_output\n",
        "\n",
        "lstm = LSTM()\n",
        "print(lstm)\n",
        "\n",
        "optimizer = torch.optim.Adam(lstm.parameters(), lr=LR, weight_decay=l2)   # optimize all parameters\n",
        "loss_func = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE1jY8rSbwqd",
        "outputId": "5d75cb4f-4ec3-4a95-8c5c-80416a212ad9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:  0 |train loss: 2.3791  train ACC: 0.2159 | test loss: 2.2634 test ACC: 0.4631 | AUC: 0.5017\n",
            "Epoch:  10 |train loss: 1.9680  train ACC: 0.4652 | test loss: 1.9529 test ACC: 0.4631 | AUC: 0.5003\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "import time\n",
        "\n",
        "# Ensure that numpy is imported at the top or before using it in the one_hot function\n",
        "def one_hot(y_):\n",
        "    y_ = y_.reshape(len(y_))\n",
        "    n_values = int(np.max(y_) + 1)  # Explicitly cast to int\n",
        "    return np.eye(n_values)[np.array(y_, dtype=np.int32)]\n",
        "\n",
        "\n",
        "best_acc = []\n",
        "best_auc = []\n",
        "\n",
        "# training and testing\n",
        "start_time = time.perf_counter()\n",
        "for epoch in range(EPOCH):\n",
        "    for step, (train_x, train_y) in enumerate(train_loader):\n",
        "        output = lstm(train_x)  # LSTM output of training data\n",
        "        loss = loss_func(output, train_y.long())  # cross entropy loss\n",
        "        optimizer.zero_grad()  # clear gradients for this training step\n",
        "        loss.backward()  # backpropagation, compute gradients\n",
        "        optimizer.step()  # apply gradients\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        test_output = lstm(test_fea_norm1)  # LSTM output of test data\n",
        "        test_loss = loss_func(test_output, test_label.long())\n",
        "\n",
        "        test_y_score = one_hot(test_label.data.cpu().numpy())  # .cpu() can be removed if your device is cpu.\n",
        "        pred_score = F.softmax(test_output, dim=1).data.cpu().numpy()  # normalize the output\n",
        "        auc_score = roc_auc_score(test_y_score, pred_score)\n",
        "\n",
        "        pred_y = torch.max(test_output, 1)[1].data.cpu().numpy()\n",
        "        pred_train = torch.max(output, 1)[1].data.cpu().numpy()\n",
        "\n",
        "        test_acc = accuracy_score(test_label.data.cpu().numpy(), pred_y)\n",
        "        train_acc = accuracy_score(train_y.data.cpu().numpy(), pred_train)\n",
        "\n",
        "        print('Epoch: ', epoch, '|train loss: %.4f' % loss.item(),\n",
        "              ' train ACC: %.4f' % train_acc, '| test loss: %.4f' % test_loss.item(),\n",
        "              'test ACC: %.4f' % test_acc, '| AUC: %.4f' % auc_score)\n",
        "        best_acc.append(test_acc)\n",
        "        best_auc.append(auc_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYZU5FCbrq_X",
        "outputId": "dc1cb41b-0840-432f-ea39-7f5fa6332101"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00      1723\n",
            "         1.0       0.00      0.00      0.00      1669\n",
            "         2.0       0.00      0.00      0.00      2569\n",
            "         3.0       0.00      0.00      0.00      2393\n",
            "         4.0       0.00      0.00      0.00      2556\n",
            "         5.0       0.00      0.00      0.00      2451\n",
            "         6.0       0.00      0.00      0.00      2547\n",
            "         7.0       0.00      0.00      0.00      2348\n",
            "         8.0       0.00      0.00      0.00      2277\n",
            "         9.0       0.00      0.00      0.00      2688\n",
            "        10.0       0.46      1.00      0.63     20033\n",
            "\n",
            "    accuracy                           0.46     43254\n",
            "   macro avg       0.04      0.09      0.06     43254\n",
            "weighted avg       0.21      0.46      0.29     43254\n",
            "\n",
            "BEST TEST ACC: 0.46314791695565727, AUC: 0.501723568892474\n",
            "Total Running Time: 298.64 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Sam\\miniconda3\\envs\\pytgpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\Sam\\miniconda3\\envs\\pytgpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\Sam\\miniconda3\\envs\\pytgpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "current_time = time.perf_counter()\n",
        "running_time = current_time - start_time\n",
        "print(classification_report(test_label.data.cpu().numpy(), pred_y))\n",
        "print('BEST TEST ACC: {}, AUC: {}'.format(max(best_acc), max(best_auc)))\n",
        "print(\"Total Running Time: {} seconds\".format(round(running_time, 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFezSiupuh5o"
      },
      "source": [
        "### CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QceHCDGzemCr",
        "outputId": "7c7f490c-c699-47be-e1c3-6589e3f9d501"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv1d(3, 16, kernel_size=(4,), stride=(1,), padding=(2,))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv1d(16, 32, kernel_size=(2,), stride=(1,), padding=(1,))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (out): Linear(in_features=128, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # First 1D convolutional layer sequence\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv1d(\n",
        "                in_channels=3,  # As your data has 3 features/channels per time step\n",
        "                out_channels=16,\n",
        "                kernel_size=4,\n",
        "                stride=1,\n",
        "                padding=2  # Adjust padding to control the output size\n",
        "            ),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(4)  # Pooling to reduce the sequence length\n",
        "        )\n",
        "        # Second 1D convolutional layer sequence\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv1d(16, 32, kernel_size=2, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2)  # Further reduce the sequence length\n",
        "        )\n",
        "        # Adjust the following numbers based on the output size from conv2\n",
        "        self.fc = nn.Linear(32 * 8, 128)  # You will need to calculate the correct size here\n",
        "        self.out = nn.Linear(128, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the output for the fully connected layer\n",
        "\n",
        "        x = F.relu(self.fc(x))\n",
        "        x = F.dropout(x, 0.2)  # Apply dropout\n",
        "\n",
        "        output = self.out(x)\n",
        "        return output, x  # Returns both the final output and the feature vector before the output layer\n",
        "\n",
        "# Create an instance of CNN\n",
        "cnn = CNN()\n",
        "print(cnn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mejcfi8Xut-E",
        "outputId": "b43765b9-6fac-4e70-9d61-ab05fb2570c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:  0 |train loss: 0.6932  train ACC: 0.4980 | test loss: 0.6937 test ACC: 0.4985 | AUC: 0.5354\n",
            "Epoch:  10 |train loss: 0.6909  train ACC: 0.5133 | test loss: 0.6908 test ACC: 0.5387 | AUC: 0.6295\n",
            "Epoch:  20 |train loss: 0.6664  train ACC: 0.6995 | test loss: 0.6609 test ACC: 0.6426 | AUC: 0.7683\n",
            "Epoch:  30 |train loss: 0.5859  train ACC: 0.7073 | test loss: 0.5749 test ACC: 0.7228 | AUC: 0.7915\n",
            "Epoch:  40 |train loss: 0.5234  train ACC: 0.7319 | test loss: 0.5271 test ACC: 0.7412 | AUC: 0.8177\n",
            "Epoch:  50 |train loss: 0.4948  train ACC: 0.7584 | test loss: 0.4978 test ACC: 0.7532 | AUC: 0.8322\n",
            "Epoch:  60 |train loss: 0.4637  train ACC: 0.7770 | test loss: 0.4710 test ACC: 0.7772 | AUC: 0.8531\n",
            "Epoch:  70 |train loss: 0.4531  train ACC: 0.7867 | test loss: 0.4675 test ACC: 0.7741 | AUC: 0.8667\n",
            "Epoch:  80 |train loss: 0.4324  train ACC: 0.8012 | test loss: 0.4365 test ACC: 0.8024 | AUC: 0.8772\n",
            "Epoch:  90 |train loss: 0.4183  train ACC: 0.8091 | test loss: 0.4293 test ACC: 0.8082 | AUC: 0.8831\n",
            "Epoch:  100 |train loss: 0.4145  train ACC: 0.8094 | test loss: 0.4424 test ACC: 0.7953 | AUC: 0.8884\n"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR, weight_decay=l2)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "best_acc = []\n",
        "best_auc = []\n",
        "\n",
        "# training and testing\n",
        "start_time = time.perf_counter()\n",
        "for epoch in range(EPOCH):\n",
        "    for step, (train_x, train_y) in enumerate(train_loader):\n",
        "\n",
        "        output = cnn(train_x)[0]  # CNN output of training data\n",
        "        loss = loss_func(output, train_y.long())  # cross entropy loss\n",
        "        optimizer.zero_grad()  # clear gradients for this training step\n",
        "        loss.backward()  # backpropagation, compute gradients\n",
        "        optimizer.step()  # apply gradients\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        test_output = cnn(test_fea_norm1)[0]  # CNN output of test data\n",
        "        test_loss = loss_func(test_output, test_label.long())\n",
        "\n",
        "        test_y_score = one_hot(test_label.data.cpu().numpy())  # .cpu() can be removed if your device is cpu.\n",
        "        pred_score = F.softmax(test_output, dim=1).data.cpu().numpy()  # normalize the output\n",
        "        auc_score = roc_auc_score(test_y_score, pred_score)\n",
        "\n",
        "        pred_y = torch.max(test_output, 1)[1].data.cpu().numpy()\n",
        "        pred_train = torch.max(output, 1)[1].data.cpu().numpy()\n",
        "\n",
        "        test_acc = accuracy_score(test_label.data.cpu().numpy(), pred_y)\n",
        "        train_acc = accuracy_score(train_y.data.cpu().numpy(), pred_train)\n",
        "\n",
        "\n",
        "        print('Epoch: ', epoch,  '|train loss: %.4f' % loss.item(),\n",
        "              ' train ACC: %.4f' % train_acc, '| test loss: %.4f' % test_loss.item(),\n",
        "              'test ACC: %.4f' % test_acc, '| AUC: %.4f' % auc_score)\n",
        "        best_acc.append(test_acc)\n",
        "        best_auc.append(auc_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDTu7u_Xuu93",
        "outputId": "97e3f61a-a0bd-451c-c1c8-5e481c0aefa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.72      0.78      1622\n",
            "         1.0       0.76      0.87      0.81      1632\n",
            "\n",
            "    accuracy                           0.80      3254\n",
            "   macro avg       0.80      0.80      0.79      3254\n",
            "weighted avg       0.80      0.80      0.79      3254\n",
            "\n",
            "BEST TEST ACC: 0.8082360172095882, AUC: 0.8883928436510238\n",
            "Total Running Time: 66.26 seconds\n"
          ]
        }
      ],
      "source": [
        "current_time = time.perf_counter()\n",
        "running_time = current_time - start_time\n",
        "print(classification_report(test_label.data.cpu().numpy(), pred_y))\n",
        "print('BEST TEST ACC: {}, AUC: {}'.format(max(best_acc), max(best_auc)))\n",
        "print(\"Total Running Time: {} seconds\".format(round(running_time, 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfXw1NE7w5QN"
      },
      "source": [
        "## GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3q6T66IWw8go",
        "outputId": "ab84fa56-2709-453e-acbb-bd46344e2e8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GRU(\n",
            "  (gru_layer): GRU(64, 128, num_layers=2, batch_first=True)\n",
            "  (out): Linear(in_features=128, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# classifier\n",
        "class GRU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GRU, self).__init__()\n",
        "\n",
        "        self.gru_layer = nn.GRU(\n",
        "            input_size=no_feature,\n",
        "            hidden_size=n_hidden,\n",
        "            num_layers=2,\n",
        "            bias=True,\n",
        "            batch_first=True,       # input & output will has batch size as 1s dimension. e.g. (batch, segment_length, no_feature)\n",
        "        )\n",
        "\n",
        "        self.out = nn.Linear(n_hidden, n_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        r_out, (h_n, h_c) = self.gru_layer(x.float(), None)\n",
        "        r_out = F.dropout(r_out, 0.3)\n",
        "        test_output = self.out(r_out[:, -1, :]) # choose r_out at the last time step\n",
        "        return test_output\n",
        "\n",
        "gru = GRU()\n",
        "print(gru)\n",
        "\n",
        "optimizer = torch.optim.Adam(gru.parameters(), lr=LR, weight_decay=l2)   # optimize all parameters\n",
        "loss_func = nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eqmd7XskxVA0",
        "outputId": "4ca28580-e0c6-42a0-f446-95a93a107240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:  0 |train loss: 0.6966  train ACC: 0.4997 | test loss: 0.7995 test ACC: 0.4991 | AUC: 0.4959\n",
            "Epoch:  10 |train loss: 0.6951  train ACC: 0.4996 | test loss: 0.6969 test ACC: 0.5009 | AUC: 0.4975\n",
            "Epoch:  20 |train loss: 0.6932  train ACC: 0.4975 | test loss: 0.6928 test ACC: 0.5061 | AUC: 0.5185\n",
            "Epoch:  30 |train loss: 0.6932  train ACC: 0.4983 | test loss: 0.6934 test ACC: 0.5052 | AUC: 0.5031\n",
            "Epoch:  40 |train loss: 0.6930  train ACC: 0.5067 | test loss: 0.6931 test ACC: 0.4969 | AUC: 0.5024\n",
            "Epoch:  50 |train loss: 0.6930  train ACC: 0.5036 | test loss: 0.6929 test ACC: 0.5129 | AUC: 0.5196\n",
            "Epoch:  60 |train loss: 0.6930  train ACC: 0.5075 | test loss: 0.6930 test ACC: 0.5098 | AUC: 0.5103\n",
            "Epoch:  70 |train loss: 0.6930  train ACC: 0.5130 | test loss: 0.6931 test ACC: 0.5071 | AUC: 0.5075\n",
            "Epoch:  80 |train loss: 0.6929  train ACC: 0.5140 | test loss: 0.6930 test ACC: 0.5108 | AUC: 0.5136\n",
            "Epoch:  90 |train loss: 0.6928  train ACC: 0.5137 | test loss: 0.6930 test ACC: 0.5123 | AUC: 0.5145\n",
            "Epoch:  100 |train loss: 0.6929  train ACC: 0.5160 | test loss: 0.6929 test ACC: 0.5104 | AUC: 0.5150\n",
            "Epoch:  110 |train loss: 0.6929  train ACC: 0.5093 | test loss: 0.6929 test ACC: 0.5068 | AUC: 0.5141\n",
            "Epoch:  120 |train loss: 0.6927  train ACC: 0.5189 | test loss: 0.6927 test ACC: 0.5184 | AUC: 0.5273\n",
            "Epoch:  130 |train loss: 0.6926  train ACC: 0.5271 | test loss: 0.6926 test ACC: 0.5246 | AUC: 0.5270\n",
            "Epoch:  140 |train loss: 0.6925  train ACC: 0.5239 | test loss: 0.6924 test ACC: 0.5258 | AUC: 0.5362\n",
            "Epoch:  150 |train loss: 0.6921  train ACC: 0.5284 | test loss: 0.6923 test ACC: 0.5175 | AUC: 0.5289\n",
            "Epoch:  160 |train loss: 0.6916  train ACC: 0.5303 | test loss: 0.6918 test ACC: 0.5240 | AUC: 0.5338\n",
            "Epoch:  170 |train loss: 0.6908  train ACC: 0.5222 | test loss: 0.6912 test ACC: 0.5178 | AUC: 0.5411\n",
            "Epoch:  180 |train loss: 0.6913  train ACC: 0.5171 | test loss: 0.6907 test ACC: 0.5369 | AUC: 0.5443\n",
            "Epoch:  190 |train loss: 0.6898  train ACC: 0.5348 | test loss: 0.6896 test ACC: 0.5400 | AUC: 0.5492\n",
            "Epoch:  200 |train loss: 0.6916  train ACC: 0.5126 | test loss: 0.6932 test ACC: 0.5025 | AUC: 0.5456\n",
            "Epoch:  210 |train loss: 0.6923  train ACC: 0.5313 | test loss: 0.6923 test ACC: 0.5111 | AUC: 0.5448\n",
            "Epoch:  220 |train loss: 0.6909  train ACC: 0.5202 | test loss: 0.6907 test ACC: 0.5172 | AUC: 0.5509\n",
            "Epoch:  230 |train loss: 0.6890  train ACC: 0.5406 | test loss: 0.6885 test ACC: 0.5341 | AUC: 0.5532\n",
            "Epoch:  240 |train loss: 0.6913  train ACC: 0.5206 | test loss: 0.6914 test ACC: 0.5255 | AUC: 0.5531\n",
            "Epoch:  250 |train loss: 0.6925  train ACC: 0.5087 | test loss: 0.6922 test ACC: 0.5123 | AUC: 0.5533\n",
            "Epoch:  260 |train loss: 0.6912  train ACC: 0.5397 | test loss: 0.6910 test ACC: 0.5295 | AUC: 0.5595\n",
            "Epoch:  270 |train loss: 0.6894  train ACC: 0.5309 | test loss: 0.6888 test ACC: 0.5320 | AUC: 0.5576\n",
            "Epoch:  280 |train loss: 0.6878  train ACC: 0.5444 | test loss: 0.6876 test ACC: 0.5366 | AUC: 0.5568\n",
            "Epoch:  290 |train loss: 0.6934  train ACC: 0.4999 | test loss: 0.6926 test ACC: 0.5086 | AUC: 0.5393\n",
            "Epoch:  300 |train loss: 0.6933  train ACC: 0.4996 | test loss: 0.6933 test ACC: 0.5009 | AUC: 0.5119\n",
            "Epoch:  310 |train loss: 0.6930  train ACC: 0.5034 | test loss: 0.6930 test ACC: 0.5031 | AUC: 0.5221\n",
            "Epoch:  320 |train loss: 0.6923  train ACC: 0.5292 | test loss: 0.6921 test ACC: 0.5366 | AUC: 0.5554\n",
            "Epoch:  330 |train loss: 0.6912  train ACC: 0.5418 | test loss: 0.6907 test ACC: 0.5516 | AUC: 0.5611\n",
            "Epoch:  340 |train loss: 0.6882  train ACC: 0.5369 | test loss: 0.6878 test ACC: 0.5369 | AUC: 0.5583\n",
            "Epoch:  350 |train loss: 0.6935  train ACC: 0.5013 | test loss: 0.6918 test ACC: 0.5154 | AUC: 0.5567\n",
            "Epoch:  360 |train loss: 0.6926  train ACC: 0.5032 | test loss: 0.6923 test ACC: 0.5243 | AUC: 0.5472\n",
            "Epoch:  370 |train loss: 0.6918  train ACC: 0.5204 | test loss: 0.6916 test ACC: 0.5387 | AUC: 0.5540\n",
            "Epoch:  380 |train loss: 0.6906  train ACC: 0.5319 | test loss: 0.6902 test ACC: 0.5347 | AUC: 0.5603\n",
            "Epoch:  390 |train loss: 0.6880  train ACC: 0.5437 | test loss: 0.6882 test ACC: 0.5341 | AUC: 0.5579\n",
            "Epoch:  400 |train loss: 0.6880  train ACC: 0.5370 | test loss: 0.6882 test ACC: 0.5289 | AUC: 0.5616\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.56      0.28      0.37      1624\n",
            "         1.0       0.52      0.78      0.62      1630\n",
            "\n",
            "    accuracy                           0.53      3254\n",
            "   macro avg       0.54      0.53      0.50      3254\n",
            "weighted avg       0.54      0.53      0.50      3254\n",
            "\n",
            "BEST TEST ACC: 0.5516287645974186, AUC: 0.5616248035600955\n",
            "Total Running Time: 443.26 seconds\n"
          ]
        }
      ],
      "source": [
        "best_auc = []\n",
        "\n",
        "# training and testing\n",
        "start_time = time.perf_counter()\n",
        "for epoch in range(EPOCH):\n",
        "    for step, (train_x, train_y) in enumerate(train_loader):\n",
        "\n",
        "        output = gru(train_x)  # GRU output of training data\n",
        "        loss = loss_func(output, train_y.long())  # cross entropy loss\n",
        "        optimizer.zero_grad()  # clear gradients for this training step\n",
        "        loss.backward()  # backpropagation, compute gradients\n",
        "        optimizer.step()  # apply gradients\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        test_output = gru(test_fea_norm1)  # GRU output of test data\n",
        "        test_loss = loss_func(test_output, test_label.long())\n",
        "\n",
        "        test_y_score = one_hot(test_label.data.cpu().numpy())\n",
        "        pred_score = F.softmax(test_output, dim=1).data.cpu().numpy()  # normalize the output\n",
        "        auc_score = roc_auc_score(test_y_score, pred_score)\n",
        "\n",
        "        pred_y = torch.max(test_output, 1)[1].data.cpu().numpy()\n",
        "        pred_train = torch.max(output, 1)[1].data.cpu().numpy()\n",
        "\n",
        "        test_acc = accuracy_score(test_label.data.cpu().numpy(), pred_y)\n",
        "        train_acc = accuracy_score(train_y.data.cpu().numpy(), pred_train)\n",
        "\n",
        "        print('Epoch: ', epoch, '|train loss: %.4f' % loss.data.item(),\n",
        "              ' train ACC: %.4f' % train_acc, '| test loss: %.4f' % test_loss.item(),\n",
        "              'test ACC: %.4f' % test_acc, '| AUC: %.4f' % auc_score)\n",
        "        best_acc.append(test_acc)\n",
        "        best_auc.append(auc_score)\n",
        "current_time = time.perf_counter()\n",
        "running_time = current_time - start_time\n",
        "\n",
        "print(classification_report(test_label.data.numpy(), pred_y))\n",
        "print('BEST TEST ACC: {}, AUC: {}'.format(max(best_acc), max(best_auc)))\n",
        "print(\"Total Running Time: {} seconds\".format(round(running_time, 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCEL7LJyl2V9"
      },
      "source": [
        "## Classifier - CSP"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
