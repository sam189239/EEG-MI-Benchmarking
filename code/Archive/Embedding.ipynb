{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mne networkx node2vec numpy pywt scikit-learn matplotlib tensorflow\n"
      ],
      "metadata": {
        "id": "G3eQ9CX0rMH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Embedding\n",
        "- Step 1: Preprocessing EEG Data\n",
        "- Step 2: Constructing a Graph from EEG Data\n",
        "- Step 3: Applying Node2Vec for Graph Embedding\n",
        "- Step 4: Using Embeddings in Further Analysis\n",
        "\n",
        "Clustering with K-Means is sensitive to the choice of n_clusters. You might need to experiment with this value to find the most meaningful clustering for your data."
      ],
      "metadata": {
        "id": "Vl3w1ICsr6fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mne  # EEG data processing library\n",
        "\n",
        "def load_and_preprocess_eeg_data(file_path):\n",
        "    # Placeholder function\n",
        "    # Load your EEG data here and perform necessary preprocessing\n",
        "    # For instance, filtering, artifact removal, etc.\n",
        "    # Return the preprocessed EEG data\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "l4zlkkBsshKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddWoB_z0UP4X"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "\n",
        "def create_eeg_graph(eeg_data):\n",
        "    num_electrodes = eeg_data.shape[0]  # Assuming eeg_data is (electrodes x samples)\n",
        "    G = nx.Graph()\n",
        "\n",
        "    # Add nodes\n",
        "    for i in range(num_electrodes):\n",
        "        G.add_node(i)\n",
        "\n",
        "    # Add edges with correlation as weights (simplified example)\n",
        "    for i in range(num_electrodes):\n",
        "        for j in range(i + 1, num_electrodes):\n",
        "            corr = np.corrcoef(eeg_data[i], eeg_data[j])[0, 1]\n",
        "            G.add_edge(i, j, weight=corr)\n",
        "    return G\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from node2vec import Node2Vec\n",
        "\n",
        "def apply_node2vec(graph, dimensions=64, walk_length=30, num_walks=200, workers=4):\n",
        "    node2vec = Node2Vec(graph, dimensions=dimensions, walk_length=walk_length,\n",
        "                        num_walks=num_walks, workers=workers)\n",
        "    model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "9Xf4S4rsq8QS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with the actual file path to your EEG data\n",
        "eeg_file_path = 'path_to_your_eeg_data_file'\n",
        "\n",
        "# Load and preprocess the EEG data\n",
        "eeg_data = load_and_preprocess_eeg_data(eeg_file_path)\n",
        "\n",
        "# Create a graph from the EEG data\n",
        "eeg_graph = create_eeg_graph(eeg_data)\n",
        "\n",
        "# Apply Node2Vec to the graph\n",
        "node2vec_model = apply_node2vec(eeg_graph)\n",
        "\n",
        "# Extract embeddings for each node (electrode)\n",
        "embeddings = np.array([node2vec_model.wv[str(i)] for i in range(num_electrodes)])\n",
        "\n",
        "# Embeddings can now be used in further machine learning tasks\n"
      ],
      "metadata": {
        "id": "TwtoRGOMsmNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Assume 'embeddings' is the numpy array of your graph embeddings\n",
        "# Set the number of clusters\n",
        "n_clusters = 10\n",
        "\n",
        "# Initialize the KMeans model\n",
        "clustering_model = KMeans(n_clusters=n_clusters)\n",
        "\n",
        "# Fit the model to your embeddings\n",
        "clustering_model.fit(embeddings)\n",
        "\n",
        "# The cluster labels for each point in the embedding\n",
        "cluster_labels = clustering_model.labels_\n"
      ],
      "metadata": {
        "id": "C0mBqkbArAu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA (Principal Component Analysis) Embedding\n",
        "\n",
        "### PCA is a straightforward linear technique for reducing dimensionality by projecting data onto the principal components.\n",
        "\n",
        "- Step 1: Load EEG Data\n",
        "- Step 2: Apply PCA\n",
        "- Step 3: Visualizing the Results\n",
        "- Step 4: Putting It All Together\n",
        "\n",
        "If you've set n_components to 2 or 3, you'll also see a plot visualizing the PCA-embedded data.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jd5Bu8vtt9OW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_eeg_data(filepath):\n",
        "    # Replace this with your EEG data loading logic\n",
        "    return np.load(filepath)\n"
      ],
      "metadata": {
        "id": "TcbNR7iPt9s6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def apply_pca(eeg_data, n_components):\n",
        "    pca = PCA(n_components=n_components)\n",
        "    return pca.fit_transform(eeg_data), pca\n"
      ],
      "metadata": {
        "id": "xH6CptE_uLL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_embeddings(embeddings, title='PCA Embedding of EEG Data'):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    if embeddings.shape[1] == 2:\n",
        "        plt.scatter(embeddings[:, 0], embeddings[:, 1])\n",
        "        plt.xlabel('Principal Component 1')\n",
        "        plt.ylabel('Principal Component 2')\n",
        "    elif embeddings.shape[1] == 3:\n",
        "        ax = plt.axes(projection='3d')\n",
        "        ax.scatter3D(embeddings[:, 0], embeddings[:, 1], embeddings[:, 2])\n",
        "        ax.set_xlabel('Principal Component 1')\n",
        "        ax.set_ylabel('Principal Component 2')\n",
        "        ax.set_zlabel('Principal Component 3')\n",
        "    plt.title(title)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "aY0h8anjuwAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution\n",
        "if __name__ == '__main__':\n",
        "    # Load EEG data\n",
        "    filepath = 'path_to_your_eeg_data.npy'  # Update with your file path\n",
        "    eeg_data = load_eeg_data(filepath)\n",
        "\n",
        "    # Apply PCA\n",
        "    n_components = 2  # Adjust based on your needs\n",
        "    eeg_embedded, pca_model = apply_pca(eeg_data, n_components)\n",
        "\n",
        "    # Print the transformed data\n",
        "    print(\"Transformed EEG Data:\\n\", eeg_embedded)\n",
        "\n",
        "    # Print the explained variance ratio\n",
        "    print(\"\\nExplained Variance Ratio per Principal Component:\", pca_model.explained_variance_ratio_)\n",
        "\n",
        "    # Optionally, plot the embeddings\n",
        "    plot_embeddings(eeg_embedded)\n"
      ],
      "metadata": {
        "id": "y_06tYZrux49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# t-SNE (t-Distributed Stochastic Neighbor Embedding)\n",
        "\n",
        "### t-SNE is a nonlinear technique particularly well suited for the visualization of high-dimensional datasets.\n",
        "\n",
        "- Step 1: Load EEG Data\n",
        "- Step 2: Apply t-SNE\n",
        "- Step 3: Visualizing the results\n",
        "- Step 4: Combine everything\n",
        "\n",
        "t-SNE parameters, particularly n_components and perplexity, can significantly affect the results. Adjust these based on the specifics of your data and the desired granularity of the embedding.\n",
        "\n"
      ],
      "metadata": {
        "id": "M79ha7DXw7eU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_eeg_data(filepath):\n",
        "    # Replace this with your actual code to load EEG data\n",
        "    return np.load(filepath)\n"
      ],
      "metadata": {
        "id": "52w0CI00xUM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def apply_tsne(eeg_data, n_components=2, perplexity=30, n_iter=1000):\n",
        "    tsne = TSNE(n_components=n_components, perplexity=perplexity, n_iter=n_iter)\n",
        "    return tsne.fit_transform(eeg_data)\n"
      ],
      "metadata": {
        "id": "oSENQGOexXZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_embeddings(embeddings, title='t-SNE Embedding of EEG Data'):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    if embeddings.shape[1] == 2:\n",
        "        plt.scatter(embeddings[:, 0], embeddings[:, 1])\n",
        "        plt.xlabel('t-SNE Component 1')\n",
        "        plt.ylabel('t-SNE Component 2')\n",
        "    elif embeddings.shape[1] == 3:\n",
        "        ax = plt.axes(projection='3d')\n",
        "        ax.scatter3D(embeddings[:, 0], embeddings[:, 1], embeddings[:, 2])\n",
        "        ax.set_xlabel('t-SNE Component 1')\n",
        "        ax.set_ylabel('t-SNE Component 2')\n",
        "        ax.set_zlabel('t-SNE Component 3')\n",
        "    plt.title(title)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "VmV90QkXxZH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution\n",
        "if __name__ == '__main__':\n",
        "    # Load EEG data\n",
        "    filepath = 'path_to_your_eeg_data.npy'  # Replace with your file path\n",
        "    eeg_data = load_eeg_data(filepath)\n",
        "\n",
        "    # Apply t-SNE\n",
        "    n_components = 2  # Set to 2 for 2D visualization, 3 for 3D\n",
        "    eeg_embedded = apply_tsne(eeg_data, n_components)\n",
        "\n",
        "    # Optionally, plot the embeddings\n",
        "    plot_embeddings(eeg_embedded)\n"
      ],
      "metadata": {
        "id": "uQoMUaqqxbHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autoencoder for Non-linear Embedding\n",
        "\n",
        "### Autoencoders can learn nonlinear embeddings, which might be more effective for complex EEG patterns.\n",
        "\n",
        "- Step 1: Load EEG Data\n",
        "- Step 2: Build the Autoencoder\n",
        "- Step 3: Train the Autoencoder\n",
        "- Step 4: Embed the EEG Data\n",
        "- Step 5: Combine and run\n",
        "\n",
        "The encoding_dim parameter, as well as the architecture of the autoencoder, can be tuned based on your data and the desired complexity of the model.\n"
      ],
      "metadata": {
        "id": "4_T1FKOQyMFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_eeg_data(filepath):\n",
        "    # Replace this with your actual code to load EEG data\n",
        "    return np.load(filepath)\n"
      ],
      "metadata": {
        "id": "vMoTmd_hyMfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "def build_autoencoder(input_dim, encoding_dim):\n",
        "    encoder = Sequential([\n",
        "        Dense(encoding_dim, activation='relu', input_shape=(input_dim,))\n",
        "    ])\n",
        "\n",
        "    decoder = Sequential([\n",
        "        Dense(input_dim, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    autoencoder = Sequential([encoder, decoder])\n",
        "    autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    return autoencoder, encoder\n"
      ],
      "metadata": {
        "id": "Oh8Q0pnszQhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_autoencoder(autoencoder, eeg_data, epochs=50, batch_size=256):\n",
        "    autoencoder.fit(eeg_data, eeg_data, epochs=epochs, batch_size=batch_size, shuffle=True)\n"
      ],
      "metadata": {
        "id": "U_mQJbF6zT5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_eeg_data(encoder, eeg_data):\n",
        "    return encoder.predict(eeg_data)\n"
      ],
      "metadata": {
        "id": "-GbozImizViW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    filepath = 'path_to_your_eeg_data.npy'  # Update this with your file path\n",
        "    eeg_data = load_eeg_data(filepath)\n",
        "\n",
        "    input_dim = eeg_data.shape[1]  # Number of features in your EEG data\n",
        "    encoding_dim = 64  # Size of the encoding layer\n",
        "\n",
        "    autoencoder, encoder = build_autoencoder(input_dim, encoding_dim)\n",
        "    train_autoencoder(autoencoder, eeg_data, epochs=50, batch_size=256)\n",
        "\n",
        "    eeg_embedded = encode_eeg_data(encoder, eeg_data)\n",
        "    print(\"Embedded EEG Data:\\n\", eeg_embedded)\n"
      ],
      "metadata": {
        "id": "0Ue1yvsrzXJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wavelet Transform for Time-Frequency Embedding\n",
        "\n",
        "### Wavelet transforms are useful for time-frequency analysis of EEG signals.\n",
        "\n",
        "- Step 1: Load EEG Data\n",
        "- Step 2: Apply Wavelet Transform\n",
        "- Step 3: Combine and Run\n",
        "\n",
        "**Wavelet Choice: Different mother wavelets (like 'db4', 'coif5', etc.) can be experimented with to see which works best for your EEG data.**\n",
        "\n",
        "**Level of Decomposition: The level of decomposition in the Wavelet Transform (level=5 here) might need adjustment based on your data's sampling rate and characteristics.**"
      ],
      "metadata": {
        "id": "i9Ay8Zr3zsBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_eeg_data(filepath):\n",
        "    # Replace this with actual code to load EEG data\n",
        "    return np.load(filepath)\n"
      ],
      "metadata": {
        "id": "y9q7Sl5w0wZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pywt\n",
        "\n",
        "def wavelet_transform(eeg_signal, wavelet_name='db4', level=5):\n",
        "    # Apply DWT and extract coefficients\n",
        "    coefficients = pywt.wavedec(eeg_signal, wavelet_name, level=level)\n",
        "    # Flatten the coefficients into a single vector\n",
        "    flattened_coefficients = np.concatenate([coef.flatten() for coef in coefficients])\n",
        "    return flattened_coefficients\n",
        "\n",
        "def apply_wavelet_to_eeg_data(eeg_data, wavelet_name='db4', level=5):\n",
        "    transformed_data = np.array([wavelet_transform(signal, wavelet_name, level) for signal in eeg_data])\n",
        "    return transformed_data\n"
      ],
      "metadata": {
        "id": "y3H7B7Tx06kE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    filepath = 'path_to_your_eeg_data.npy'  # Update this with your file path\n",
        "    eeg_data = load_eeg_data(filepath)\n",
        "\n",
        "    # Apply Wavelet Transform to each EEG signal\n",
        "    wavelet_name = 'db4'  # Mother wavelet\n",
        "    level = 5  # Decomposition level\n",
        "    eeg_embedded = apply_wavelet_to_eeg_data(eeg_data, wavelet_name, level)\n",
        "\n",
        "    print(\"Wavelet Transformed EEG Data:\\n\", eeg_embedded)\n"
      ],
      "metadata": {
        "id": "nYO4ZR77074A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Triplet loss"
      ],
      "metadata": {
        "id": "5aAKXRnX3faW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def load_eeg_data():\n",
        "    # Load your EEG data here\n",
        "    # EEG data should be in a format suitable for your network (e.g., 2D or 3D arrays)\n",
        "    # For this example, let's assume it returns EEG data and their labels\n",
        "    pass\n",
        "\n",
        "def create_triplets(eeg_data, labels):\n",
        "    # Create triplets (anchor, positive, negative)\n",
        "    # You will need to write this function based on how your EEG data and labels are structured\n",
        "    pass\n",
        "\n",
        "eeg_data, labels = load_eeg_data()\n",
        "triplets = create_triplets(eeg_data, labels)"
      ],
      "metadata": {
        "id": "mF47L7NP31LA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def triplet_loss(margin):\n",
        "    def loss(y_true, y_pred):\n",
        "        anchor, positive, negative = y_pred[:, 0], y_pred[:, 1], y_pred[:, 2]\n",
        "        pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=-1)\n",
        "        neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=-1)\n",
        "        return tf.maximum(pos_dist - neg_dist + margin, 0)\n",
        "    return loss\n",
        "\n",
        "def create_model(input_shape, encoding_dim):\n",
        "    base_input = Input(shape=input_shape)\n",
        "    x = Dense(128, activation='relu')(base_input)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    encoded = Dense(encoding_dim, activation='sigmoid')(x)\n",
        "\n",
        "    base_model = Model(base_input, encoded)\n",
        "\n",
        "    input_anchor = Input(shape=input_shape)\n",
        "    input_positive = Input(shape=input_shape)\n",
        "    input_negative = Input(shape=input_shape)\n",
        "\n",
        "    encoded_anchor = base_model(input_anchor)\n",
        "    encoded_positive = base_model(input_positive)\n",
        "    encoded_negative = base_model(input_negative)\n",
        "\n",
        "    merged_output = Lambda(lambda x: tf.stack([x[0], x[1], x[2]], axis=1))([encoded_anchor, encoded_positive, encoded_negative])\n",
        "\n",
        "    model = Model(inputs=[input_anchor, input_positive, input_negative], outputs=merged_output)\n",
        "    model.compile(loss=triplet_loss(margin=1.0), optimizer=Adam(0.0001))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Assuming EEG data has been preprocessed to have a uniform shape\n",
        "input_shape = eeg_data[0][0].shape  # Replace with actual input shape\n",
        "encoding_dim = 32  # Size of the embedding\n",
        "\n",
        "model = create_model(input_shape, encoding_dim)\n"
      ],
      "metadata": {
        "id": "sg396CCv38Xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def triplet_loss(margin):\n",
        "    def loss(y_true, y_pred):\n",
        "        anchor, positive, negative = y_pred[:, 0], y_pred[:, 1], y_pred[:, 2]\n",
        "        pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=-1)\n",
        "        neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=-1)\n",
        "        return tf.maximum(pos_dist - neg_dist + margin, 0)\n",
        "    return loss\n",
        "\n",
        "def create_model(input_shape, encoding_dim):\n",
        "    base_input = Input(shape=input_shape)\n",
        "    x = Dense(128, activation='relu')(base_input)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    encoded = Dense(encoding_dim, activation='sigmoid')(x)\n",
        "\n",
        "    base_model = Model(base_input, encoded)\n",
        "\n",
        "    input_anchor = Input(shape=input_shape)\n",
        "    input_positive = Input(shape=input_shape)\n",
        "    input_negative = Input(shape=input_shape)\n",
        "\n",
        "    encoded_anchor = base_model(input_anchor)\n",
        "    encoded_positive = base_model(input_positive)\n",
        "    encoded_negative = base_model(input_negative)\n",
        "\n",
        "    merged_output = Lambda(lambda x: tf.stack([x[0], x[1], x[2]], axis=1))([encoded_anchor, encoded_positive, encoded_negative])\n",
        "\n",
        "    model = Model(inputs=[input_anchor, input_positive, input_negative], outputs=merged_output)\n",
        "    model.compile(loss=triplet_loss(margin=1.0), optimizer=Adam(0.0001))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Assuming EEG data has been preprocessed to have a uniform shape\n",
        "input_shape = eeg_data[0][0].shape  # Replace with actual input shape\n",
        "encoding_dim = 32  # Size of the embedding\n",
        "\n",
        "model = create_model(input_shape, encoding_dim)\n"
      ],
      "metadata": {
        "id": "FzmTT-Ky4BCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract anchor, positive, negative from triplets for training\n",
        "anchor_data = np.array([triplet[0] for triplet in triplets])\n",
        "positive_data = np.array([triplet[1] for triplet in triplets])\n",
        "negative_data = np.array([triplet[2] for triplet in triplets])\n",
        "\n",
        "# Dummy labels, not used in loss calculation\n",
        "dummy_labels = np.empty((anchor_data.shape[0], 3))\n",
        "\n",
        "model.fit([anchor_data, positive_data, negative_data], dummy_labels, epochs=10, batch_size=32)\n"
      ],
      "metadata": {
        "id": "6SuKwdi53iAZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}