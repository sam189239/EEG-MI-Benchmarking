{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7cGDJ0YJiZbc"
      },
      "outputs": [],
      "source": [
        "from scipy.signal import butter, lfilter\n",
        "import scipy\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as Data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import time\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OtUtmxdg-Gw"
      },
      "source": [
        "# Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_path = \"../Data/Physionet_processed/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTGqHXL4grJT",
        "outputId": "e4f633b4-1b67-492b-d4fc-eb41811e48c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The shape of Dataset_1: (259520, 65)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[-16, -29,   2, ..., -11,  15,   0],\n",
              "       [-56, -54, -27, ...,   1,  21,   0],\n",
              "       [-55, -55, -29, ...,  18,  35,   0],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,   0,   0,   9],\n",
              "       [  0,   0,   0, ...,   0,   0,   9],\n",
              "       [  0,   0,   0, ...,   0,   0,   9]], dtype=int64)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_1=np.load(data_path + '1.npy')\n",
        "print('The shape of Dataset_1:', dataset_1.shape)\n",
        "dataset_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIhUIGnmhJ3B"
      },
      "source": [
        "# Filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FdntZhsDp4yN"
      },
      "outputs": [],
      "source": [
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = scipy.signal.lfilter(b, a, data)\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io9Emc6khOOZ",
        "outputId": "4cd3233e-6bcd-432c-ef1f-66bf029a5854"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The shape of filtered feature: (259520, 64)\n",
            "The shape of dataset_1 after filtering: (259520, 65)\n"
          ]
        }
      ],
      "source": [
        "n_fea = 64  # 64 channels\n",
        "label = dataset_1[:, n_fea: n_fea+1]  # seperate label from feature\n",
        "feature = dataset_1[:, 0:n_fea]\n",
        "feature_f=[]  # feature after filtering\n",
        "\n",
        "# EEG Delta pattern decomposition\n",
        "for i in range(feature.shape[1]):\n",
        "    x = feature[:, i]\n",
        "    fs = 160.0\n",
        "    lowcut = 0.5\n",
        "    highcut = 4.0\n",
        "    y = butter_bandpass_filter(x, lowcut, highcut, fs, order=3)\n",
        "    feature_f.append(y)\n",
        "\n",
        "feature_f=np.array(feature_f).T\n",
        "print('The shape of filtered feature:',feature_f.shape)\n",
        "\n",
        "data_f=np.hstack((feature_f,label))  # stack label to filtered feature\n",
        "print(\"The shape of dataset_1 after filtering:\",data_f.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GG7DFm-LpWiR"
      },
      "outputs": [],
      "source": [
        "def extract(input, n_classes, n_fea, time_window, moving):\n",
        "    xx = input[:, :n_fea]\n",
        "    yy = input[:, n_fea:n_fea + 1]\n",
        "    new_x = []\n",
        "    new_y = []\n",
        "    number = int((xx.shape[0] / moving) - 1)\n",
        "    for i in range(number):\n",
        "        ave_y = np.average(yy[int(i * moving):int(i * moving + time_window)])\n",
        "        if ave_y in range(n_classes + 1):\n",
        "            new_x.append(xx[int(i * moving):int(i * moving + time_window), :])\n",
        "            new_y.append(ave_y)\n",
        "        else:\n",
        "            new_x.append(xx[int(i * moving):int(i * moving + time_window), :])\n",
        "            new_y.append(0)\n",
        "\n",
        "    new_x = np.array(new_x)\n",
        "    new_x = new_x.reshape([-1, n_fea * time_window])\n",
        "    new_y = np.array(new_y)\n",
        "    new_y.shape = [new_y.shape[0], 1]\n",
        "    data = np.hstack((new_x, new_y))\n",
        "    data = np.vstack((data, data[-1]))  # add the last sample again, to make the sample number round\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_reucTkyhjBk",
        "outputId": "d7f77299-3d48-44b1-91fd-12fa4ab279b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After segmentation, the shape of the data: (173013, 193)\n"
          ]
        }
      ],
      "source": [
        "n_class = 10  # 0~9 classes ('10:rest' is not considered)\n",
        "segment_length = 3  # selected time window; 16=160*0.1\n",
        "\n",
        "# segment data, check more details about the 'extract' function in BCI_functions.ipynb\n",
        "data_seg = extract(dataset_1, n_classes=n_class, n_fea=n_fea, time_window=segment_length, moving=(segment_length/2))  # 50% overlapping\n",
        "\n",
        "print('After segmentation, the shape of the data:', data_seg.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEf16DdRoOyH",
        "outputId": "7852f959-173e-4326-f2eb-c2f5d717c1b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After segmentation, the shape of the data: (173013, 193)\n"
          ]
        }
      ],
      "source": [
        "# remove instance with label==10 (rest)\n",
        "# removed_label = [2,3,4,5,6,7,8,9,10]  #2,3,4,5,\n",
        "# for ll in removed_label:\n",
        "#     id = dataset_1[:, -1]!=ll\n",
        "#     dataset_1 = dataset_1[id]\n",
        "\n",
        "# data segmentation\n",
        "# n_class = int(11-len(removed_label))  # 0~9 classes ('10:rest' is not considered)\n",
        "no_feature = 64  # the number of the features\n",
        "segment_length = 3  # selected time window; 16=160*0.1\n",
        "LR = 0.005  # learning rate\n",
        "EPOCH = 401\n",
        "\n",
        "data_seg = extract(dataset_1, n_classes=n_class, n_fea=no_feature, time_window=segment_length, moving=(segment_length/2))  # 50% overlapping\n",
        "print('After segmentation, the shape of the data:', data_seg.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1HexifPPoqmZ"
      },
      "outputs": [],
      "source": [
        "# split training and test data\n",
        "no_longfeature = no_feature*segment_length\n",
        "data_seg_feature = data_seg[:, :no_longfeature]\n",
        "data_seg_label = data_seg[:, no_longfeature:no_longfeature+1]\n",
        "train_feature, test_feature, train_label, test_label = train_test_split(data_seg_feature, data_seg_label, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3T_BOalozSU",
        "outputId": "dca99ee8-7658-4214-c51d-730b972c81ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ -30.,  -18.,    3., ..., -115.,  -88.,  -96.],\n",
              "       [ -26.,  -17.,   -6., ...,  -47.,  -55.,  -10.],\n",
              "       [  40.,   48.,   29., ...,   58.,   92.,   59.],\n",
              "       ...,\n",
              "       [  58.,   58.,   66., ...,   24.,  -20.,   14.],\n",
              "       [  43.,   77.,   88., ...,  -15.,    6.,  -92.],\n",
              "       [ -84.,  -68.,  -56., ...,   33.,   51.,   19.]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbGkmEYiozIe",
        "outputId": "56559d94-b3c9-42ee-9074-9cbbfbe30581"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 13.,  14., -11., ...,  -8., -54., -96.],\n",
              "       [-50., -48., -37., ...,  12.,  54., 124.],\n",
              "       [-23., -20., -40., ..., -22.,  -1., -12.],\n",
              "       ...,\n",
              "       [-36., -26., -18., ...,  32., -32., -13.],\n",
              "       [  9., -32., -28., ..., -43., -32.,   2.],\n",
              "       [ 72.,  58.,  48., ...,  44.,  30.,  40.]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsuleu7vh6rc"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsa8SoRtoK4b",
        "outputId": "40f0c8d1-f71a-4f2b-f2d7-246af02c6a81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After normalization, the shape of training feature: (129759, 192) \n",
            "After normalization, the shape of test feature: (43254, 192)\n",
            "After reshape, the shape of training feature: (129759, 3, 64) \n",
            "After reshape, the shape of test feature: (43254, 3, 64)\n"
          ]
        }
      ],
      "source": [
        "# normalization\n",
        "# before normalize reshape data back to raw data shape\n",
        "train_feature_2d = train_feature.reshape([-1, no_feature])\n",
        "test_feature_2d = test_feature.reshape([-1, no_feature])\n",
        "\n",
        "# min-max normalization\n",
        "scaler3 = MinMaxScaler().fit(train_feature)\n",
        "train_fea_norm1 = scaler3.transform(train_feature)\n",
        "test_fea_norm1 = scaler3.transform(test_feature)\n",
        "print('After normalization, the shape of training feature:', train_fea_norm1.shape,\n",
        "      '\\nAfter normalization, the shape of test feature:', test_fea_norm1.shape)\n",
        "\n",
        "# after normalization, reshape data to 3d in order to feed in to LSTM\n",
        "train_fea_norm1 = train_fea_norm1.reshape([-1, segment_length, no_feature])\n",
        "test_fea_norm1 = test_fea_norm1.reshape([-1, segment_length, no_feature])\n",
        "print('After reshape, the shape of training feature:', train_fea_norm1.shape,\n",
        "      '\\nAfter reshape, the shape of test feature:', test_fea_norm1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vyrwygUCiNiq"
      },
      "outputs": [],
      "source": [
        "BATCH_size = train_fea_norm1.shape[0] # use test_data as batch size\n",
        "\n",
        "# feed data into dataloader\n",
        "train_fea_norm1 = torch.tensor(train_fea_norm1).type('torch.FloatTensor')\n",
        "train_label = torch.tensor(train_label.flatten())\n",
        "train_data = Data.TensorDataset(train_fea_norm1, train_label)\n",
        "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_size, shuffle=False)\n",
        "\n",
        "test_fea_norm1 = torch.tensor(test_fea_norm1).type('torch.FloatTensor')\n",
        "test_label = torch.tensor(test_label.flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmVdVuCLh_mA"
      },
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5OR8JfSGk2ur"
      },
      "outputs": [],
      "source": [
        "def one_hot(y_):\n",
        "    y_ = y_.reshape(len(y_))\n",
        "    y_ = [int(xx) for xx in y_]\n",
        "    n_values = np.max(y_) + 1\n",
        "    return np.eye(n_values)[np.array(y_, dtype=np.int32)]\n",
        "    import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "bzbWP7YEqR8K"
      },
      "outputs": [],
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(no_feature*segment_length, 64*4),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(64*4, no_feature*segment_length),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return encoded, decoded\n",
        "\n",
        "autoencoder = AutoEncoder()\n",
        "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=LR)\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "best_acc = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIWSi7uPrUV3"
      },
      "source": [
        "## Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qRDFYEV3s0Cm"
      },
      "outputs": [],
      "source": [
        "# n_class = int(11-len(removed_label))  # 0~9 classes ('10:rest' is not considered)\n",
        "no_feature = 64  # the number of the features\n",
        "segment_length = 3  # selected time window; 16=160*0.1\n",
        "LR = 0.005  # learning rate\n",
        "EPOCH = 101\n",
        "n_hidden = 128  # number of neurons in hidden layer\n",
        "l2 = 0.001  # the coefficient of l2-norm regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll7S-aCwulOK"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSjcrArVrT5h",
        "outputId": "c9b1d0da-7ba8-44c6-9f24-11f90a841d41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LSTM(\n",
            "  (lstm_layer): LSTM(64, 128, num_layers=2, batch_first=True)\n",
            "  (out): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LSTM, self).__init__()\n",
        "\n",
        "        self.lstm_layer = nn.LSTM(\n",
        "            input_size=no_feature,\n",
        "            hidden_size=n_hidden,         # LSTM hidden unit\n",
        "            num_layers=2,           # number of LSTM layer\n",
        "            bias=True,\n",
        "            batch_first=True,       # input & output will has batch size as 1s dimension. e.g. (batch, segment_length, no_feature)\n",
        "        )\n",
        "\n",
        "        self.out = nn.Linear(n_hidden, n_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        r_out, (h_n, h_c) = self.lstm_layer(x.float(), None)\n",
        "        r_out = F.dropout(r_out, 0.3)\n",
        "\n",
        "        test_output = self.out(r_out[:, -1, :]) # choose r_out at the last time step\n",
        "        return test_output\n",
        "\n",
        "lstm = LSTM()\n",
        "print(lstm)\n",
        "\n",
        "optimizer = torch.optim.Adam(lstm.parameters(), lr=LR, weight_decay=l2)   # optimize all parameters\n",
        "loss_func = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "QKr5-ybarmeW",
        "outputId": "7ddf1ad2-389b-4918-9890-fcfac1cda284"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "Target 10 is out of bounds.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[21], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, (train_x, train_y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m      9\u001b[0m     output \u001b[38;5;241m=\u001b[39m lstm(train_x)  \u001b[38;5;66;03m# LSTM output of training data\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# cross entropy loss\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# clear gradients for this training step\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# backpropagation, compute gradients\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Sam\\miniconda3\\envs\\pytgpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Sam\\miniconda3\\envs\\pytgpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Sam\\miniconda3\\envs\\pytgpu\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Sam\\miniconda3\\envs\\pytgpu\\lib\\site-packages\\torch\\nn\\functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mIndexError\u001b[0m: Target 10 is out of bounds."
          ]
        }
      ],
      "source": [
        "best_acc = []\n",
        "best_auc = []\n",
        "\n",
        "# training and testing\n",
        "start_time = time.perf_counter()\n",
        "for epoch in range(EPOCH):\n",
        "    for step, (train_x, train_y) in enumerate(train_loader):\n",
        "\n",
        "        output = lstm(train_x)  # LSTM output of training data\n",
        "        loss = loss_func(output, train_y.long())  # cross entropy loss\n",
        "        optimizer.zero_grad()  # clear gradients for this training step\n",
        "        loss.backward()  # backpropagation, compute gradients\n",
        "        optimizer.step()  # apply gradients\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        test_output = lstm(test_fea_norm1)  # LSTM output of test data\n",
        "        test_loss = loss_func(test_output, test_label.long())\n",
        "\n",
        "        test_y_score = one_hot(test_label.data.cpu().numpy())  # .cpu() can be removed if your device is cpu.\n",
        "        pred_score = F.softmax(test_output, dim=1).data.cpu().numpy()  # normalize the output\n",
        "        auc_score = roc_auc_score(test_y_score, pred_score)\n",
        "\n",
        "        pred_y = torch.max(test_output, 1)[1].data.cpu().numpy()\n",
        "        pred_train = torch.max(output, 1)[1].data.cpu().numpy()\n",
        "\n",
        "        test_acc = accuracy_score(test_label.data.cpu().numpy(), pred_y)\n",
        "        train_acc = accuracy_score(train_y.data.cpu().numpy(), pred_train)\n",
        "\n",
        "\n",
        "        print('Epoch: ', epoch, '|train loss: %.4f' % loss.item(),\n",
        "              ' train ACC: %.4f' % train_acc, '| test loss: %.4f' % test_loss.item(),\n",
        "              'test ACC: %.4f' % test_acc, '| AUC: %.4f' % auc_score)\n",
        "        best_acc.append(test_acc)\n",
        "        best_auc.append(auc_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYZU5FCbrq_X"
      },
      "outputs": [],
      "source": [
        "current_time = time.perf_counter()\n",
        "running_time = current_time - start_time\n",
        "print(classification_report(test_label.data.cpu().numpy(), pred_y))\n",
        "print('BEST TEST ACC: {}, AUC: {}'.format(max(best_acc), max(best_auc)))\n",
        "print(\"Total Running Time: {} seconds\".format(round(running_time, 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFezSiupuh5o"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQbV4iZtuTuI",
        "outputId": "d2f0c886-7aa7-4e6b-fa02-7ec109bc69de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(2, 4), stride=(1, 1), padding=(1, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=(2, 4), stride=(2, 4), padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=1024, out_features=128, bias=True)\n",
            "  (out): Linear(in_features=128, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=1,\n",
        "                out_channels=16,\n",
        "                kernel_size=(2,4),\n",
        "                stride=1,\n",
        "                padding= (1,2)  #([1,2]-1)/2,\n",
        "            ),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2,4))\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, (2,2), stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2))\n",
        "        )\n",
        "        self.fc = nn.Linear(4*8*32, 128)  # 64*2*4\n",
        "        self.out = nn.Linear(128, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        x = F.relu(self.fc(x))\n",
        "        x = F.dropout(x, 0.2)\n",
        "\n",
        "        output = self.out(x)\n",
        "        return output, x\n",
        "\n",
        "cnn = CNN()\n",
        "print(cnn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "mejcfi8Xut-E",
        "outputId": "79038e30-6979-45d5-cfdd-bb9b7d98fbf3"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Given groups=1, weight of size [16, 1, 2, 4], expected input[1, 129759, 3, 64] to have 1 channels, but got 129759 channels instead",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[23], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCH):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, (train_x, train_y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m---> 12\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# CNN output of training data\u001b[39;00m\n\u001b[0;32m     13\u001b[0m         loss \u001b[38;5;241m=\u001b[39m loss_func(output, train_y\u001b[38;5;241m.\u001b[39mlong())  \u001b[38;5;66;03m# cross entropy loss\u001b[39;00m\n\u001b[0;32m     14\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# clear gradients for this training step\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Sam\\miniconda3\\envs\\pytgpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Sam\\miniconda3\\envs\\pytgpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[22], line 24\u001b[0m, in \u001b[0;36mCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 24\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)\n\u001b[0;32m     26\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\Sam\\miniconda3\\envs\\pytgpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Sam\\miniconda3\\envs\\pytgpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Sam\\miniconda3\\envs\\pytgpu\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\Sam\\miniconda3\\envs\\pytgpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Sam\\miniconda3\\envs\\pytgpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Sam\\miniconda3\\envs\\pytgpu\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Sam\\miniconda3\\envs\\pytgpu\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [16, 1, 2, 4], expected input[1, 129759, 3, 64] to have 1 channels, but got 129759 channels instead"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR, weight_decay=l2)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "best_acc = []\n",
        "best_auc = []\n",
        "\n",
        "# training and testing\n",
        "start_time = time.perf_counter()\n",
        "for epoch in range(EPOCH):\n",
        "    for step, (train_x, train_y) in enumerate(train_loader):\n",
        "\n",
        "        output = cnn(train_x)[0]  # CNN output of training data\n",
        "        loss = loss_func(output, train_y.long())  # cross entropy loss\n",
        "        optimizer.zero_grad()  # clear gradients for this training step\n",
        "        loss.backward()  # backpropagation, compute gradients\n",
        "        optimizer.step()  # apply gradients\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        test_output = cnn(test_fea_norm1)[0]  # CNN output of test data\n",
        "        test_loss = loss_func(test_output, test_label.long())\n",
        "\n",
        "        test_y_score = one_hot(test_label.data.cpu().numpy())  # .cpu() can be removed if your device is cpu.\n",
        "        pred_score = F.softmax(test_output, dim=1).data.cpu().numpy()  # normalize the output\n",
        "        auc_score = roc_auc_score(test_y_score, pred_score)\n",
        "\n",
        "        pred_y = torch.max(test_output, 1)[1].data.cpu().numpy()\n",
        "        pred_train = torch.max(output, 1)[1].data.cpu().numpy()\n",
        "\n",
        "        test_acc = accuracy_score(test_label.data.cpu().numpy(), pred_y)\n",
        "        train_acc = accuracy_score(train_y.data.cpu().numpy(), pred_train)\n",
        "\n",
        "\n",
        "        print('Epoch: ', epoch,  '|train loss: %.4f' % loss.item(),\n",
        "              ' train ACC: %.4f' % train_acc, '| test loss: %.4f' % test_loss.item(),\n",
        "              'test ACC: %.4f' % test_acc, '| AUC: %.4f' % auc_score)\n",
        "        best_acc.append(test_acc)\n",
        "        best_auc.append(auc_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDTu7u_Xuu93"
      },
      "outputs": [],
      "source": [
        "current_time = time.perf_counter()\n",
        "running_time = current_time - start_time\n",
        "print(classification_report(test_label.data.cpu().numpy(), pred_y))\n",
        "print('BEST TEST ACC: {}, AUC: {}'.format(max(best_acc), max(best_auc)))\n",
        "print(\"Total Running Time: {} seconds\".format(round(running_time, 2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
