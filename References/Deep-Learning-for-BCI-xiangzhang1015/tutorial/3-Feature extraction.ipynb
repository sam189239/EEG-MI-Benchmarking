{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><font size=10>Feature extraction</font><br/>\n",
    "\n",
    "Feature extraction refers to the process of extracting discriminating features from the input signals through domain knowledge. Traditional features are extracted from time-domain (e.g., variance, mean value, kurtosis), frequency-domain (e.g., fast Fourier transform), and timefrequency domains (e.g., discrete wavelet transform). They will enrich distinguishable information regarding user intention.[<sup>1</sup>](#refer-anchor-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Manual-feature-extraction\" data-toc-modified-id=\"Manual-feature-extraction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Manual feature extraction</a></span></li><li><span><a href=\"#Automatical-feature-extraction\" data-toc-modified-id=\"Automatical-feature-extraction-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Automatical feature extraction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Autoencoder\" data-toc-modified-id=\"Autoencoder-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Autoencoder</a></span></li></ul></li><li><span><a href=\"#Reference\" data-toc-modified-id=\"Reference-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Reference</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual feature extraction \n",
    "Manual feature extraction is highly dependent on the domain knowledge. For example, neuroscience knowledge is required to extract distinctive features from motor imagery EEG signals. Manual feature extraction is also time-consuming and difficult. When manually extract feature from brain signals, some discriminating features such as time-frequency features, wavelet entropy and band-specific power are common choices.\n",
    "\n",
    "One of the advantages of deep learning is that it can automatically learn the informative features and discover underlying patterns without domain knowledge. In this tutorial, we only introduce how to learn representative features from raw data and not discuss traditional feature extractions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatical feature extraction\n",
    "\n",
    "Representative deep learning models, which learn the pure and representative features automatically from the input data.\n",
    "These algorithms only have the function of feature extraction but cannot make classification.\n",
    " \n",
    "> As the figure[<sup>1</sup>](#refer-anchor-1) shown below:  \n",
    "Representative models can be divided into Authoencoder (AE), Restricted Boltzmann Machine (RBM), and Deep Belief Networks (DBN). D-AE denotes DeepAutoencoder which refers to the Autoencoder with multiple hidden layers. Likewise, D-RBM denotes Deep-Restricted Boltzmann Machine with multiple hidden layers. Deep Belief Network can be composed of AE or RBM, therefore, we divided DBN into DBN-AE and DBN-RBM.\n",
    "\n",
    "![avatar](https://raw.githubusercontent.com/xiangzhang1015/ML_BCI_tutorial/main/tutorial/dlm.PNG)\n",
    "\n",
    "__Commonly used deep learning algorithms for representation are AE, RBM, DBN, along with their variations.__  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder\n",
    "In this part, as an example of unsupervised feature extraction via deep learning, we will present the implementation of a simple framework that use AE as a feature extractor and feed the learned features to a standard KNN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_1 shape: (259520, 65)\n",
      "After segmentation, the shape of the data: (4880, 513)\n",
      "After normalization, the shape of training feature: (3660, 512) \n",
      "After normalization, the shape of test feature: (1220, 512)\n",
      "After reshape, the shape of training feature: (3660, 8, 64) \n",
      "After reshape, the shape of test feature: (1220, 8, 64)\n",
      "Epoch:  0 | STEP:  0 |Autoencoder train loss: 0.0177 |KNN accuracy: 0.4951\n",
      "Epoch:  50 | STEP:  0 |Autoencoder train loss: 0.0075 |KNN accuracy: 0.6369\n",
      "Epoch:  100 | STEP:  0 |Autoencoder train loss: 0.0034 |KNN accuracy: 0.7238\n",
      "Epoch:  150 | STEP:  0 |Autoencoder train loss: 0.0059 |KNN accuracy: 0.7016\n",
      "Epoch:  200 | STEP:  0 |Autoencoder train loss: 0.0069 |KNN accuracy: 0.6713\n",
      "Epoch:  250 | STEP:  0 |Autoencoder train loss: 0.0018 |KNN accuracy: 0.7393\n",
      "Epoch:  300 | STEP:  0 |Autoencoder train loss: 0.0018 |KNN accuracy: 0.7508\n",
      "Epoch:  350 | STEP:  0 |Autoencoder train loss: 0.0020 |KNN accuracy: 0.7516\n",
      "Epoch:  400 | STEP:  0 |Autoencoder train loss: 0.0044 |KNN accuracy: 0.7082\n",
      "BEST TEST ACC: 0.7516393442622951\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import myimporter\n",
    "from BCI_functions import *  # BCI_functions.ipynb contains some functions we might use multiple times in this tutorial\n",
    "\n",
    "dataset_1 = np.load('1.npy')\n",
    "print('dataset_1 shape:', dataset_1.shape)\n",
    "\n",
    "# remove instance with label==10 (rest)\n",
    "removed_label = [2,3,4,5,6,7,8,9,10]  #2,3,4,5,\n",
    "for ll in removed_label:\n",
    "    id = dataset_1[:, -1]!=ll\n",
    "    dataset_1 = dataset_1[id]\n",
    "\n",
    "# data segmentation\n",
    "n_class = int(11-len(removed_label))  # 0~9 classes ('10:rest' is not considered)\n",
    "no_feature = 64  # the number of the features\n",
    "segment_length = 8  # selected time window; 16=160*0.1\n",
    "LR = 0.005  # learning rate\n",
    "EPOCH = 401\n",
    "\n",
    "data_seg = extract(dataset_1, n_classes=n_class, n_fea=no_feature, time_window=segment_length, moving=(segment_length/2))  # 50% overlapping\n",
    "print('After segmentation, the shape of the data:', data_seg.shape)\n",
    "\n",
    "# split training and test data\n",
    "no_longfeature = no_feature*segment_length\n",
    "data_seg_feature = data_seg[:, :no_longfeature]\n",
    "data_seg_label = data_seg[:, no_longfeature:no_longfeature+1]\n",
    "train_feature, test_feature, train_label, test_label = train_test_split(data_seg_feature, data_seg_label, shuffle=True)\n",
    "\n",
    "# normalization\n",
    "# before normalize reshape data back to raw data shape\n",
    "train_feature_2d = train_feature.reshape([-1, no_feature])\n",
    "test_feature_2d = test_feature.reshape([-1, no_feature])\n",
    "\n",
    "# min-max normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler3 = MinMaxScaler().fit(train_feature)\n",
    "train_fea_norm1 = scaler3.transform(train_feature)\n",
    "test_fea_norm1 = scaler3.transform(test_feature)\n",
    "print('After normalization, the shape of training feature:', train_fea_norm1.shape,\n",
    "      '\\nAfter normalization, the shape of test feature:', test_fea_norm1.shape)\n",
    "\n",
    "# after normalization, reshape data to 3d in order to feed in to LSTM\n",
    "train_fea_norm1 = train_fea_norm1.reshape([-1, segment_length, no_feature])\n",
    "test_fea_norm1 = test_fea_norm1.reshape([-1, segment_length, no_feature])\n",
    "print('After reshape, the shape of training feature:', train_fea_norm1.shape,\n",
    "      '\\nAfter reshape, the shape of test feature:', test_fea_norm1.shape)\n",
    "\n",
    "BATCH_size = train_fea_norm1.shape[0] # use test_data as batch size\n",
    "\n",
    "# feed data into dataloader\n",
    "train_fea_norm1 = torch.tensor(train_fea_norm1).type('torch.FloatTensor')\n",
    "train_label = torch.tensor(train_label.flatten())\n",
    "train_data = Data.TensorDataset(train_fea_norm1, train_label)\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_size, shuffle=False)\n",
    "\n",
    "test_fea_norm1 = torch.tensor(test_fea_norm1).type('torch.FloatTensor')\n",
    "test_label = torch.tensor(test_label.flatten())\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(no_feature*segment_length, 64*4),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(64*4, no_feature*segment_length),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "autoencoder = AutoEncoder()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=LR)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "best_acc = []\n",
    "\n",
    "# classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "# training and testing\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (train_x, train_y) in enumerate(train_loader):\n",
    "\n",
    "        train_x = train_x.view(-1, no_feature*segment_length)\n",
    "        train_encoded, train_decoded = autoencoder(train_x)\n",
    "\n",
    "        loss = loss_func(train_decoded, train_x)  # mean square error\n",
    "        optimizer.zero_grad()  # clear gradients for this training step\n",
    "        loss.backward()  # backpropagation, compute gradients\n",
    "        optimizer.step()  # apply gradients\n",
    "\n",
    "        if epoch % 50 == 0 :\n",
    "            knn.fit(train_encoded.data.numpy(), train_y.data.numpy())\n",
    "            test_fea_norm1 = test_fea_norm1.view(-1, no_feature*segment_length)\n",
    "            test_encoded, test_decoded = autoencoder(test_fea_norm1)\n",
    "            knn_acc = knn.score(test_encoded.data.numpy(), test_label.data.numpy())\n",
    "\n",
    "            print('Epoch: ', epoch, '| STEP: ', step, '|Autoencoder train loss: %.4f' % loss.item(),'|KNN accuracy: %.4f' % knn_acc)\n",
    "            best_acc.append(knn_acc)\n",
    "\n",
    "print('BEST TEST ACC: {}'.format(max(best_acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_As we can see from above, the experiment performence of this combination is not good. The reason for this may trace to the characteristic of the dataset. However, for different dataset such as ones with fMRI data, autoencoder may achieve better performence._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "<div id=\"refer-anchor-1\"></div>\n",
    "\n",
    "- [1]  [Zhang, X., Yao, L., Wang, X., Monaghan, J.J., Mcalpine, D. and Zhang, Y., 2020. A survey on deep learning-based non-invasive brain signals: recent advances and new frontiers. Journal of Neural Engineering.](https://iopscience.iop.org/article/10.1088/1741-2552/abc902/meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
